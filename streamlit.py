import streamlit as st
import numpy as np
import pickle

@st.cache_resource
def load_embeddings():
    # è®€å–å‘é‡èˆ‡å­—å…¸
    vectors = np.load("vectors.npy")

    with open("word2idx.pkl", "rb") as f:
        word2idx = pickle.load(f)

    with open("idx2word.pkl", "rb") as f:
        idx2word = pickle.load(f)

    # åš L2 æ­£è¦åŒ–ï¼Œè®“ cosine similarity è®Šæˆå–®ç´”çš„å…§ç©
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    norms = np.where(norms == 0, 1e-8, norms)
    vectors_norm = vectors / norms

    return vectors_norm, word2idx, idx2word


vectors, word2idx, idx2word = load_embeddings()


def most_similar(word, topn=10):
    word = word.lower()

    if word not in word2idx:
        return []

    idx = word2idx[word]

    # å–å‡ºç›®æ¨™å‘é‡
    target_vec = vectors[idx]

    # è¨ˆç®— cosine similarityï¼ˆå› ç‚ºå·²ç¶“æ­£è¦åŒ–ï¼Œå¯ä»¥ç›´æ¥å…§ç©ï¼‰
    sims = vectors @ target_vec

    # æŠŠè‡ªå·±é‚£ä¸€æ ¼çš„ç›¸ä¼¼åº¦è¨­æˆ -infï¼Œä¸è¦è¢«æ’é€²çµæœ
    sims[idx] = -1.0

    # å–å‰ topn å€‹ index
    best_idx = np.argsort(sims)[::-1][:topn]

    results = []
    for i in best_idx:
        # æœ‰äº› index å¯èƒ½æ²’æœ‰å°æ‡‰çš„å­—ï¼ˆä¿éšªè™•ç†ï¼‰
        token = idx2word.get(int(i), None)
        if token is not None:
            results.append((token, float(sims[i])))

    return results


# ---------------------- Streamlit ä»‹é¢ ----------------------

st.title("Model Word2Vec")

st.write("è¼¸å…¥ä¸€å€‹è‹±æ–‡å–®å­—ï¼Œæˆ‘æœƒå¹«ä½ æ‰¾å‡ºå‘é‡ç©ºé–“è£¡æœ€ç›¸ä¼¼çš„å–®å­—ã€‚")

query = st.text_input("è«‹è¼¸å…¥å–®å­—ï¼ˆè‹±æ–‡ï¼‰:")

topn = st.slider("é¡¯ç¤ºå¹¾å€‹ç›¸ä¼¼å–®å­—", min_value=5, max_value=20, value=10)

if query:
    results = most_similar(query, topn=topn)

    if not results:
        st.warning("é€™å€‹å–®å­—ä¸åœ¨è©å½™è¡¨è£¡ï¼Œå¯èƒ½æ˜¯å¤ªå†·é–€æˆ–æœ‰æ‰“éŒ¯å­— ğŸ¥²")
    else:
        st.subheader(f"å’Œ **{query}** æœ€æ¥è¿‘çš„å–®å­—ï¼š")
        for w, score in results:
            st.write(f"- {w}  ï¼ˆcosine similarity = {score:.3f}ï¼‰")